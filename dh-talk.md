## I: Rikers

LAST SUMMER I spent a few short hours at Rikers Island Correctional Facility
together with a small group of volunteers from Columbia University. We were
there ostensibly to run an educational program. Wanting to move away from
traditional classroom arrangements, we conceived of our project, Rikers Bot,
as a digital storytelling event, combining elements of a programming workshop
and a writers group. The idea was to get folks excited about programming, to
give a measure of voice to those housed at Rikers under sometimes appalling
conditions, and to give the public at large a glimpse into an otherwise opaque
institution. Most importantly, we were there to spend a bit of time with the
young people of Rikers: an encounter with the penal system in the midst of our
community.

Even in the best of times, entering Rikers is not easy. One goes through a
series of gates and checkpoints. One laminated card is exchanged for another.
The guard stamps a mark on your wrist using invisible ink.

The jail was also not what I expected. I thought that once inside, I would
observe a state of total surveillance. Conditioned by the Foucauldian image of
the panopticon, I expected to see docile bodies, the control of activity, and
the swarming of disciplinary mechanisms. Instead, many in the group were
struck by the dilapidated, almost abandoned feeling of the grounds. At one
point, something was the matter at the main gate and we were ushered through
an alternative entrance. A guard led us through rooms filled with well-used
riot gear, past other guards eating breakfast, and through hallways lined with
hand-written bills about job safety, potlucks, and charity football games.

We were on the way to a wing of the building that housed the classrooms. But
at some point, while walking up the stairs, our guide ducked out into a side
door, which locked behind her. We waited in the stairwell. We knew where we
had to go, but the doors ahead of us and behind were locked. Standing there
quietly, together, we understood something about the jail. Despite the guards
and the cameras, it was not a place of total surveillance. The building stood
in isolation from the outside world. Our presence here was registered in a
notebook by hand. We traded our state issued identification for a piece of
paper and a stamp. We left no digital trace. In short, no one really knew we
were here.

A moment of silence on the stairs punctuated the paradox at the center of
Bernard Harcourt’s recent book, Exposed: Desire and Disobedience in the
Digital Age. Real and imaginary panopticons of incarceration from centuries
past pale in comparison with those that surround us today. Rather than
acquiescing to structures of command and surveillance by force, against our
will, and in confinement, we have surrendered to them voluntarily, without
duress, and at scale. The condition of willful exposure Harcourt describes in
his book challenges well-worn tropes of critical theory. Harcourt begins by
noting that we inhabit neither Guy Dubord’s “society of spectacle” nor Michel
Foucault’s “punitive society.” Rather, the book documents the emergence of a
“new architecture of power relations,” “knots of state-like power,” and
“mini-theaters of consumption.”

A new logic of watching and being watched brings with it novel companions: the
body double in the reflection of our devices; the quantified self; the
ever-vigilant, artificially intelligent personal assistant. Where some wear
tracking ankle bracelets in punishment, others strap on tracking wrist
bracelets in the name of health and self-discovery. Absent the noise of cell
phones and Twitter feeds, the momentary quiet of a stairwell somewhere at
Rikers evoked a visceral feeling of isolation. Rikers was scary not because it
represented order but because compared to my usually compartmentalized and
hyper-connected life it gave space to violence and disorder. “It sounds like
I’m in a zoo with all of the birds chirping,” wrote one of the young people.
“Jail makes us feel deprived and cause vagueness — lacking definite form or
character,” the bot tweeted. “All the birds outside the windows make it so
hard to hear anything.”

The banal realities of today’s surveillance surpass even the tin foil
conspiracies of yesterday. Consider the following several footnotes of my own,
not found in Harcourt’s book. A lapsed software engineer among humanists, I
continue to regularly follow news and review literature from the tech world.
Two devices that help illustrate Harcourt’s argument have caught my attention
in 2015. The first is called OnHub made by Google. The marketing materials
describe it as a “new type of router for the new way to WiFi.” It is supposed
to help you stay connected to the internet at home. The device is remarkable
for its “innovative circular antenna design,” which “provides reliable Wi-Fi
coverage in more directions in your home.” A tear-down of OnHub by engineers
at IFIXIT revealed 13 antennas, along with an ambient light sensor inside.

The second is called Echo, by Amazon. This one is a bit trickier. It is an
artificially intelligent personal assistant, similar to Apple’s Siri or
Microsoft’s Cortana, but housed in its own sleek speaker cabinet, meant for
the living room. It listens, plays music, and answers questions. “Amazon Echo
is designed around your voice,” the marketing materials read:

> It’s hands-free and always on. […] Tucked under the light ring on Echo is an
array of seven microphones. These sensors use beam forming technology to hear
you from any direction, even while music is playing. […] Echo is also an
expertly tuned speaker that can fill any room with immersive sound […] Echo is
built in the cloud, so it is always getting smarter. The more you use Echo,
the more it adapts to your speech patterns, vocabulary, and personal
preferences.

Uncharacteristically for such gadgets, both OnHub and Echo occupy a central
place in the home. Routers and speakers of this sort are usually unsightly,
rectangular affairs. They are commonly hidden out of sight, under desks or on
top of shelves. The Echo speaker and the OnHub router differ in that they cut
an attractive tower-like figure. Both are packed with sensors. The
advertisements show them placed on coffee tables and kitchen counters.

I submit two further pieces of evidence for your consideration. Two recent
papers in computer science give us an idea of the potential for surveillance
enabled by the above devices. In 2014, researchers from UC Berkley published a
paper titled “SoundLoc: Acoustic Method for Indoor Localization without
Infrastructure.” The researchers write that: “SoundLoc is a room-level
localization system that exploits the intrinsic acoustic properties of
individual rooms and obviates the needs for infrastructures.” Calling it the
“Room Impulse Response measurement system,” the researchers develop an
algorithm that uses ordinary microphones found on our laptops and cell phones
to create a “sound fingerprint” for each room and to identify the location of
its occupants. One would surmise that the seven microphones and the powerful
speakers that the Echo carries would make the device particularly well suited
for such echolocation, tracking, and fingerprinting of domestic spaces.

In 2013, a group from MIT published a similar paper titled “See Through Walls
with WiFi!” “For many years humans have fantasized about X-ray vision,” the
authors write. Could it be possible today, using wi-fi signals emitted by an
ordinary router? As it turns out, yes: “We present Wi-Vi, a wireless
technology that uses Wi-Fi signals to detect moving humans behind walls in
closed rooms.” Just a few years ago, the very idea of mapping rooms with
microphones or tracking humans behind closed doors with wireless signals would
be relegated to the pages of novel by Ian Fleming. The suggestion that
consumers would voluntarily place such capable devices in the middle of their
living rooms defies belief still, despite the evidence. Where a bug in a hotel
room caused scandals in the Nixon era, inviting a beastie that carries 13
antennas to the bedroom is now something customers will pay $170 for. The fact
that the Samsung Smart TV, the United States’s best-selling television set, is
routinely recording conversations, even when powered off, barely made the
news. The terms and conditions policy that comes with the device simply
states: “Please be aware that if your spoken words include personal or other
sensitive information, that information will be among the data captured and
transmitted to a third party through your use of Voice Recognition.”

## II. Tractors

How is a tractor like a writing desk?

There are some metaphorical niceties in the comparison between reading and
writing, and reaping and sowing. Changes in technology that facilitate
physical contact between laborers and their element, be it a blank page or a
fallow field, bring farmers and literary scholars into a more direct,
non-figurative conversation, concerning the nature of electronic goods.

In the digital world, neither plow nor pen are subject purely to their
mechanics. Modern tractors like modern typewriters are also computers, which
means that these tools now contain an inward facing surface, marked by
inscription. Solid state memory arrays are machined out of silicon, ceramic,
palladium, platinum, silver and other precious metals. They are tiny
storehouses for information---programming instructions---which ultimately
govern the behaviour of the mechanism. The presence of such a surface and the
capability to respond to its commands is what differentiates "smart" devices
from their lackwit counterparts. The smart device, to paraphrase Marx, is one
that evolves, out of its silicon brain, grotesque ideas. It is a thing imbued
with potential for symbolic manipulation.

It should not surprise us then that protections usually reserved for
intellectual property have been expanded to cover such tangible goods as
harvesters and combines. In her essay "Freedom to Tinker," Pamela Samuelson,
of Berkeley Law, described the now infamous attempt by John Deere, a major
international maker of agricultural machinery, to restrict access to the
innards of its machines, thus severely limiting its customers' ability to
repair their own equipment.[^1] Organizations such as the Electronic Frontier
Foundation and repair.org have mobilized politically, resulting in "right to
repair" bills adopted into law in at least 11 states, including New York and
Massachusetts.[^2]

These bills are important to me as a literary scholar, because the right to
repair implies, physically, the right to read, write, and interpret
inscription implicit in all smart devices, including those on our writing
desks. Like farmers, all those who read and write at a computer are faced with
a threat of critical disempowerment. The practice of literary hermeneutics,
the interpretation of texts, in all of its varied traditions, cannot take
place when access to inscription is physically curtailed. Think of it as an
ultimate form of political censorship, not by decree, but by material design.
Solid state drives are sealed hermetically and therefore hermeneutically.
What one sees at the surface of a screen is part of a more complex, laminate
figure which extends across surfaces: some near the reader and other remote,
inches and sometimes continents away from the site of interpretation. The
electronic book in my palm has its origins on servers guarded by armed men in
Ohio, Northern Virginia, Mumbai, and São Paulo.[^3]

What are the media specifics of text instantiated on digital screens? In
answering that question, I have relied on a number of archival sources that
point to an intellectual legacy shared between the history of literary thought
and the history of modern computing. In this way, I show that the very idea of
a Turing machine, crucial to the development of computer science, owes its
origins to a series of thought experiments about the nature of textual
interpretation in the work of Ludwig Wittgenstein. Elsewhere, I discuss the
influence of metaphor theory in the practice of user interface design, as
reflected in the thought of Brenda Laurel, Donald Norman, Edwin Hutchins and
other proponents of the "direct manipulation" movement, which gave us the
familiar "windows," "folders," "scroll bars," and "trash cans" on screen. I
show how the very mechanics of cathode ray tube and liquid crystal displays
affect the apprehension of digital media, including text, which moves on
screen, at the limits of "critical flicker fusion" in excess of 60 times per
second, even as it appears to stand still.

What happens when farmers lose the right to handle soil or to fix their tools?
What happens to writers who lose touch with pen and page? Can the practice of
literary interpretation persist in alienation from the material contexts of
knowledge production? These are not theoretical questions, but matters of
tactical expediency. The politics of inscription are a matter of grave concern
to farmer laborers, software engineers, and textual scholars alike. They
require a concerted effort to more closely align our ideals with technologies
at hand.

In *Plain Text* I wrote:

> The politics of inscription are not simply a matter for academic discussion.
In the time that it took me to finish this book, a coalition of US "data
dissidents" won a temporary exemption from the Digital Millennium Copyright
Act to allow them to modify their medical implants. It included Hugo Campos,
who wanted to access data collected by his Implantable Cardioverter
Defibrillator, and Ben West and Jay Radcliffe who fought for the right to
modify their implanted insulin pumps. Marie Moe, of Norway, similarly
struggled to rewrite her heart implant's software. "I want to know what code
is running inside of my body," she said. "Medical devices are black boxes,"
she continued, "you can't look into them, there's no transparency, we don't
know how they work."[^5]

> In Pakistan, the American National Security agency-sponsored Skynet program
has placed people on the US-sanctioned "disposition matrix" or "kill list"
based on predictive analytics: social network analysis, cellular machine
learning, patterns of travel and telephone use. Automated tools with names
like SMARTTRACKER, SMARTCHART, and Cloud Travel Analytic select people for
target strikes by unmanned areal vehicles.[^6] Our ability to interpret codes
that kill on our behalf also stems from our capacity to access them, read,
understand, modify, and publish criticism.

> Readers everywhere are engaged in a *political* struggle to control and deploy
codified resources. The heart and the sky are sites on which the tactics of
inscription are increasingly contested. The right to access the internals of a
device is intrinsically related to the right to interpret it. An engaged and
literate public requires the ability to keep mechanisms of power in plain
view, amendable to commentary and continual interpretation.

## III: Systems

Langdon Winner. To what extent technology is autonomous?

The view opposite of intention---the systems view---has also led to some
unpalatable and as yet not-fully thought out political commitments. For
example, the diminishing of individual human agency has played well into the
hands of private concerns, interested in limiting the legal liability of their
members. Similarly, the legal view of personhood has expanded to include
corporate assemblages, which advocate for such rights as freedom of speech and
freedom of religion [@ripken_corporations_2009; @johnson_originalism_2010].
Paradoxically, the theoretical diminution of individual agency and its related
concepts---free will, authorship, intent---has accompanied the expansion of
rights afforded to trans-human collectives, often at the expense of
marginalized persons and communities. Corporate "right" to speak by spending
money on political advertising thus clashes with our collective desire to keep
money out of politics [@noauthor_citizens_2010; @levitt_confronting_2010]. The
assertion of corporate "right to religious freedom" curtails a woman's choice
to dictate the terms of her own healthcare [@noauthor_sebelius_2013;
@sepinwall_conscience_2015]. The right to privacy afforded to hoteliers (who,
in a precedent-setting case, refused to cooperate with an official
investigation of sexual assault committed on their premises) infringes on a
victim's right to fair redress and to justice [@noauthor_patel_2013;
@adam_patel_2013]. Too often the posthuman deference to complex systems is
merely an excuse to perpetuate injustice with impunity.

In the field of artificial intelligence in particular, the temptation is to
dissolve the causal links of social responsibility. Civilian casualties in
drone warfare and financial crashes due to rapid, algorithmic trade are
presented as natural calamities: unintentional, blameless, and outside of
human control. Trans-national corporate agencies establish byzantine legal
structures with the express purpose of mitigating criminal responsibility by
those who benefit the most from every transaction. Laws in every jurisdiction
are passed routinely, as part of a convoluted documentary record meant to
benefit the few while being understood by none.

The systems metaphor conceals the logic of a pernicious social Darwinism, of
the kind that assumes, without evidence, that the rules of
speciation---selection, survival, reproduction, inheritance---will hold true
for biological as well as for ideological ecosystems. The assumption is but a
metaphor. Symbolic goods---currency and ideas---are patently not subject to
those physical laws that govern gene transfer or the survival of a species.
The comparison between systems so differently constituted may yield
interesting insights, but should not be confused for ontological equivalency
nor for science. Configurations of ink on a piece of paper are not actually
organisms: they neither compete nor cooperate for survival. Their reproduction
is at best a compelling analogy.

The confusion hinges on the distinction between natural and artificial
systems. In the first case, one is pained to articulate a notion of systemic
intent. It is hard to know, for example, what nature "wants" or what a forest
"intends" to do with its leaves. By contrast, an artificially incorporated
system, such as the Leviathan of a nation-state, is constituted through
explicitly expressed intents and purposes: a literal Constitution. The very
definition of politics in the tradition of liberal democratic thought
intrinsically relates to the struggle to more effectively articulate that
emergent collective will through mechanisms such as public deliberation and
fair elections. To place artificial systems back under the rubric of mindless
natural organisms is to take them out of politics altogether. There can be no
participatory discussion about what a forest "wants" or the fate the market
"intends" for its constituents. Organs do not have a voice in the
self-determining activity of the organism.

The distinction between natural and artificial systems is an arbitrary one, to
be sure. Like many boundaries, it dissolves under magnification. Yet, the
binary is necessary to sustain the difference between causes and effects,
those determined and those defining the terms. Almost every expression in the
definition of "design"---a plan or scheme conceived in the mind and intended
for subsequent execution---implies an active subject. Our basic everyday ideas
about truth and justice require it. The distinction between natural and
artificial designs is necessary for big ideas, such as environmental
responsibility, and for small ones, such as ticket refunds and insurance
payouts. Art entails artifice.

I join a chorus of voices---among them Langdon Winner, Cathy O'neil, Frank
Pasquale, and N. Katherine Hayles---who have argued for the importance of a
continual de-mystification of autonomous technology. If the goal of the
posthumanities is to systematically dispel the illusion of the free will, I
would like to work in the vein of a humanism in which agency, however
circumscribed by the forces of determinism, is to be rediscovered in the
complexity of the system. This is no easy task if we are to avoid the pitfalls
of an entitled anthropocentrism or crude Randian libertarianism.

In *Alien Phenomenology*, Ian Bogost, whose work I admire save for the
posthuman "object-oriented" ontological overtures, asks:

> Why do we give the dead Civil War soldier, the guilty Manhattan project
> physicist, the oval-headed alien anthropomorph, and the intelligent
> celestial race so much more credence than the scoria cone, the obsidian
> fragment, the gypsum crystal, the capsicum pepper, and the propane flame?
> [@bogost_alien_2012, 3]

Bogost is right in observing that the human perspective offers a tiny and
arbitrary vantage point onto a multifaceted universe. It is however the only
vantage available to us. Any notion of animal rights or ecological
responsibility---crystal, cone, or pepper---has to be advanced from that
precarious position. To think, as Michel Foucault warned us, that humans are
the universe's ultimate purpose, the pinnacle of cosmic evolution, is
arrogance. It is also a mistake to treat emergent natural forces as
teleologically inevitable, determinate of the human condition, or worse yet to
claim to represent their worldviews and purposes. A posthumanist cannot have
it both ways: what lies beyond human reason is either unknowable, in which
case we have no words to articulate it, or it can be known, in which case it
is not beyond human reason.

The posthuman proposition is politically as it is logically unpalatable. In
the prevailing post-neo-Hegelian worldview, something akin to a world spirit
is seen to develop by its own divine, mystic logic. Those on the extreme end
of the Hegelian perspective believe, as a matter of eschatological prophesy,
in the inevitable emergence of artificial intelligence---the
singularity---which portends not only the end of history but also the complete
technological transcendence of humanity, in a form so intelligent, in fact,
and so complex, as to exist, conveniently, beyond reproach or critique [See
@kurzweil_singularity_2006; @vinge_coming_2012]. Arguments from prophesy claim
to speak for this emerging divinity just as they maintain that it lies
necessarily outside the scope of human comprehension.

The social contract requires expressed consent, which animals, rocks, forests,
or planets cannot give. We have no option but to rely on our own, human logics
to articulate a system of ethics that nevertheless includes non-deliberative
agents. Thomas Nagel, an influential contemporary philosopher of mind, has
argued similarly about the impossibility of truly understanding the experience
of another species outside of the human perspective. Those who claim to speak
on behalf of objects or natural forces do so from within a discourse that
cannot possibly be challenged by those entities it purports to represent. The
work of Linda Alcoff, Trin T.  Min-ha, and Joyce Trebilcot reminds us that any
attempt to speak on the behalf of those who cannot speak themselves should be
suspect by default, due to an obvious and insurmountable imbalance of
discursive capacities [@alcoff_problem_1991; @trebilcot_dyke_1988;
@trinh_woman_2009].

The revised Kantian alternative is not to assert the primacy of humanity but
to recognize it as a precarious, yet the only available to us, point view from
which any ethical consideration of the world can be advanced. "We are bound to
earth through the human condition," Hannah Arendt wrote about the hubris of
what she called the cosmic, Archimedean vantage, which she located somewhere
in the galaxies above earth, at a distance that affords great leverage
[@arendt_human_2012, 262]. The trans-human vantage is a symptom of what Arendt
saw in terms of "world alienation." She wrote:

> Under this condition of remoteness, every assemblage of things is
transformed into a mere multitude, and every multitude, no matter how
disordered, incoherent and confused, will fall into certain patterns and
configurations possessing the same validity and no more significance than the
mathematical curve, which, as Leibniz once remarked, can always be found
between points thrown at random on a piece of paper [@arendt_human_2012, 267].

Arendt's thought, as ever, flows in the background of my reflections on
technology. In *The Human Condition*, I understand her to argue that to stay
grounded in an earth-bound perspective is to acknowledge the limits of the
human capacity to transform the universe in its image. It is also to deny the
narrative of inevitable "progress," bound to advance, despite all
protestations, toward prophesied ends.

Paradoxically again, Hegelian proponents of singularity view media and
technology, artificial intelligence for example, as a natural process,
synonymous with the Hegelian *Geist*. The very term "media" suggests a
substance innate to the world, such as air or water. However, artificial
media, such as film or integrated circuit, are neither wholly natural nor
wholly human-made substances. Unlike water or air they do in fact contain
"plans and schemes conceived in the mind intended for subsequent execution."
They are designed and reflect a distinctly human form of artifice. We are
therefore justified in asking: Who are they designed for? Who is excluded from
the design process?

To say that artifacts are designed is not to insist on the primacy of the
will.  Designed objects contain fragments of intent, which, once separated
from the body, are further subject to innumerable other influences. They
continue to change in unexpected and unpredictable ways. In his evocative work
on aging buildings, *How Buildings Learn*, Stewart Brand wrote that buildings
are at once "unchanging deep structure," and, in the words of Rina Swentzell,
a historian of Pueblo architecture: "flow, continual flow, continual change,
continual transformation" [@brand_how_1995, 2-3; @gillette_her_1992, 84].
Purposeful design is subject to the vagaries of time. To understand its
effects on the world, we must therefore keep in mind both its original
intended shape and its gradual, organic metamorphosis in response to natural
forces: accretion, erosion, avulsion.

"The life of gravel and sandpaper is every bit as troubled by inner
ambiguities as human existence ever was," Graham Harman wrote in his *Guerilla
Metaphysics* [@harman_guerrilla_2005, 251]. Emphatically, no. Most people
discern the obvious difference between walking on gravel and stepping on
someone's foot; between breaking a pencil and breaking someone's arm. These
intuitions reflect a concept of other minds and other mind states, such as
empathy and pain, not afforded to gravel or sandpaper. Imagine, for example,
spending time alone with a pet rock, or worse, within a rock. If stone and
steel bar are every bit as troubled by their inner ambiguities as soldiers,
physicists, or nurses, how can one argue for the exceptional cruelty of
solitary confinement? Or the injustice of mass incarceration, which
disproportionately affects people of color? What rights can vegetables have
over the need of the hungry to eat them?

Even these simple, initial hypotheticals show that our ethical and aesthetic
commitments are not flat. They have depth and gradation. They are the makings
of depth and gradation, characteristic of the human species. In a series of
experiments dating back to the ninetieth century aesthetics of Gustav Fechner,
researchers have consistently found subjects willing to make seemingly
arbitrary aesthetic distinctions, even in the selection of abstract geometric
shapes [@fechner_vorschule_1876; @mcmanus_aesthetics_1980;
@mcmanus_golden_1997]. Any notion of ethics and aesthetics necessitates a
theory of stratified value, the elevation of some goods above others: a
preference for peace over war, conversation over violence, justice over
injustice. These are necessary effects of human bias. They are attempts to
change the world, to negotiate boundaries between internal and external, to
foster a sense of membership in some sets and communities and not in others.
These attempts may be illusory, but I also understand them to be necessary to
my survival. The loss of value---a homogeneous rather than a dappled
ontology---entails complete objectification, the loss of meaning, the loss
identity, and the loss of life.
